{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ2DRg1TS_np"
      },
      "source": [
        "# Проект speech-to-text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJTV1KLsgF99"
      },
      "source": [
        "Я возьму датасет с русскоязычными аудиозаписями по ссылке https://disk.yandex.ru/d/v2Hipv7XG4fEDQ, применю к нему предобученную модель whisper-small из Hugging Face для распознавания речи и выведу транскрипции для 10 случайно выбранных аудиофайлов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ksbal\\Desktop\\HW\\GenDL\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import (\n",
        "    WhisperProcessor,\n",
        "    WhisperForConditionalGeneration,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer\n",
        ")\n",
        "import sentencepiece\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import os\n",
        "import random\n",
        "from datasets import load_dataset\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import io\n",
        "import soundfile as sf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Устанавливаем устройство\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "WhisperForConditionalGeneration(\n",
              "  (model): WhisperModel(\n",
              "    (encoder): WhisperEncoder(\n",
              "      (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
              "      (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
              "      (embed_positions): Embedding(1500, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperEncoderLayer(\n",
              "          (self_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): WhisperDecoder(\n",
              "      (embed_tokens): Embedding(51865, 768, padding_idx=50257)\n",
              "      (embed_positions): WhisperPositionalEmbedding(448, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x WhisperDecoderLayer(\n",
              "          (self_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): WhisperAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=False)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (proj_out): Linear(in_features=768, out_features=51865, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загрузка модели whisper\n",
        "whisper_processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "whisper_model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
        "forced_decoder_ids = whisper_processor.get_decoder_prompt_ids(language=\"ru\", task=\"transcribe\")\n",
        "whisper_model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "tsv_path = r\"urls_normalized.tsv\"\n",
        "# Чтение ссылок\n",
        "with open(tsv_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = [line.strip().split(\"\\t\")[0] for line in f if line.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['http://storage.mds.yandex.net:80/get-voicetoloka/1872575/197f271b-b23f-4ee0-b240-e956a172d7af',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/3d8c8d43-f7f2-479b-a857-c90faa5e2faf',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/45161c4c-3f2c-4638-940e-a69404074ebb',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/3c0ebd62-2cc1-4c9c-be63-5733511a11cd',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/6385560c-7068-45c2-9ba7-9e061249e0a4',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/c4f3178c-14b2-44f8-b36e-f34a47520e10',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/0f2ef6c9-3dec-45ae-b456-8115c9419044',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/4711cdac-8181-4f3c-8889-77cf408f3ff2',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/37e917e1-1fdf-4064-a74f-57a84bcb28b9',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/d203c652-509b-4c41-bdaf-f374e1c3c87e']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Теперь выберем 10 случайных датасетов, чтобы вывести результат работы модели\n",
        "\"\"\"\n",
        "random.seed(42)\n",
        "selected_urls = random.sample(lines, k=min(10, len(lines)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transcribe_audio(url: str) -> str:\n",
        "    \"\"\"Распознаёт речь из аудио по URL с помощью Whisper\"\"\"\n",
        "    response = requests.get(url, timeout=15)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    audio_bytes = io.BytesIO(response.content)\n",
        "    audio_np, sr = sf.read(audio_bytes, dtype='float32')\n",
        "\n",
        "    if audio_np.ndim > 1:\n",
        "        audio_np = audio_np.mean(axis=1)\n",
        "\n",
        "    if sr != 16000:\n",
        "        audio_np = librosa.resample(audio_np, orig_sr=sr, target_sr=16000)\n",
        "\n",
        "    input_features = whisper_processor(\n",
        "        audio_np, sampling_rate=16000, return_tensors=\"pt\"\n",
        "    ).input_features.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        predicted_ids = whisper_model.generate(\n",
        "            input_features,\n",
        "            forced_decoder_ids=forced_decoder_ids,\n",
        "            max_length=448\n",
        "        )\n",
        "\n",
        "    transcription = whisper_processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "    return transcription.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/eebe7151-43f7-4e5f-af3d-d7a1a3ab2197\n",
            "Распознано:     Александр Владимирович Попов\n",
            "\n",
            "[2] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/fcceeeb4-5bb7-460a-853c-99c3c7bd5aef\n",
            "Распознано:     Андрей Сахаров\n",
            "\n",
            "[3] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/3c0ebd62-2cc1-4c9c-be63-5733511a11cd\n",
            "Распознано:     Дайон Уорвик\n",
            "\n",
            "[4] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/09c0c412-2316-4bf4-9f92-8349067de618\n",
            "Распознано:     Брюс Springsteam\n",
            "\n",
            "[5] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/47b9b402-e832-438d-ad85-3f7375867e4a\n",
            "Распознано:     КОУ ПОРТЕР\n",
            "\n",
            "[6] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/86aaebac-a43a-4f80-a6e4-136bfb5492e3\n",
            "Распознано:     Голова ломка.\n",
            "\n",
            "[7] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/373c13d2-0039-4ca1-a549-1563d2a8ef0a\n",
            "Распознано:     Крестный отец 2\n",
            "\n",
            "[8] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/2a6d78d6-5b79-4ec1-bd9b-29b59c1960c1\n",
            "Распознано:     Дай не трехо.\n",
            "\n",
            "[9] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/29c0f7f4-9701-4e19-a4cd-874ec5397be1\n",
            "Распознано:     Эффект бабочки.\n",
            "\n",
            "[10] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/1f418f48-7d16-41c4-b1ec-a06ec58aacfd\n",
            "Распознано:     Старший сын\n"
          ]
        }
      ],
      "source": [
        "for i, url in enumerate(selected_urls, 1):\n",
        "    try:\n",
        "        print(f\"\\n[{i}] URL: {url}\")\n",
        "        raw_text = transcribe_audio(url)\n",
        "        print(f\"Распознано:     {raw_text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Если послушать аудио и посмотрет на текст, то можно заметить, что есть некоторые ошибки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загрузка модели исправления ошибок\n",
        "spell_tokenizer = T5Tokenizer.from_pretrained(\"UrukHan/t5-russian-spell\")\n",
        "spell_model = T5ForConditionalGeneration.from_pretrained(\"UrukHan/t5-russian-spell\")\n",
        "spell_model.to(device).eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def correct_spelling(text: str) -> str:\n",
        "    \"\"\"Исправляет орфографические ошибки в тексте с помощью T5\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    \n",
        "    input_for_model = \"Spell correct: \" + text\n",
        "    inputs = spell_tokenizer(\n",
        "        input_for_model,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=256\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = spell_model.generate(\n",
        "            **inputs,\n",
        "            max_length=256,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    corrected = spell_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return corrected.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/eebe7151-43f7-4e5f-af3d-d7a1a3ab2197\n",
            "Распознано:     Александр Владимирович Попов\n",
            "Исправлено:     Александр Владимирович Попов\n",
            "\n",
            "[2] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/fcceeeb4-5bb7-460a-853c-99c3c7bd5aef\n",
            "Распознано:     Андрей Сахаров\n",
            "Исправлено:     Андрей Сахаров\n",
            "\n",
            "[3] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/3c0ebd62-2cc1-4c9c-be63-5733511a11cd\n",
            "Распознано:     Дайон Уорвик\n",
            "Исправлено:     Дайон Уоррен\n",
            "\n",
            "[4] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/09c0c412-2316-4bf4-9f92-8349067de618\n",
            "Распознано:     Брюс Springsteam\n",
            "Исправлено:     Брюс. ringsteam.\n",
            "\n",
            "[5] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/47b9b402-e832-438d-ad85-3f7375867e4a\n",
            "Распознано:     КОУ ПОРТЕР\n",
            "Исправлено:     КОУ ПОРТЕР\n",
            "\n",
            "[6] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/86aaebac-a43a-4f80-a6e4-136bfb5492e3\n",
            "Распознано:     Голова ломка.\n",
            "Исправлено:     Голова ломка.\n",
            "\n",
            "[7] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/373c13d2-0039-4ca1-a549-1563d2a8ef0a\n",
            "Распознано:     Крестный отец 2\n",
            "Исправлено:     Крестный отец 2\n",
            "\n",
            "[8] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/2a6d78d6-5b79-4ec1-bd9b-29b59c1960c1\n",
            "Распознано:     Дай не трехо.\n",
            "Исправлено:     Дай не трех.\n",
            "\n",
            "[9] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/29c0f7f4-9701-4e19-a4cd-874ec5397be1\n",
            "Распознано:     Эффект бабочки.\n",
            "Исправлено:     Эффект бабочки.\n",
            "\n",
            "[10] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/1f418f48-7d16-41c4-b1ec-a06ec58aacfd\n",
            "Распознано:     Старший сын\n",
            "Исправлено:     Старший сын.\n"
          ]
        }
      ],
      "source": [
        "for i, url in enumerate(selected_urls, 1):\n",
        "    try:\n",
        "        print(f\"\\n[{i}] URL: {url}\")\n",
        "        raw_text = transcribe_audio(url)\n",
        "        print(f\"Распознано:     {raw_text}\")\n",
        "\n",
        "        corrected_text = correct_spelling(raw_text)\n",
        "        print(f\"Исправлено:     {corrected_text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpXtmy6GiDk3"
      },
      "source": [
        "Я соберу датасет для дообучения, используя бесплатный API Groq (или альтернативную локальную LLM, например, через Ollama, если Groq недоступен).\n",
        "Создам датасет из >1000 примеров исправления опечаток, сохраню его локально, загружу в Hugging Face через библиотеки datasets и huggingface_hub, и использую для дообучения модели с целью улучшить её качество по сравнению с предобученной версией."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6EJIcfzWL7Ox"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import time\n",
        "from groq import Groq, RateLimitError\n",
        "from datasets import load_dataset, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeWbkBn5X_xN"
      },
      "outputs": [],
      "source": [
        "os.environ[\"GROQ_API_KEY\"] = \"****\"\n",
        "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "PROMPT = (\n",
        "    'Сгенерируй ровно одну строку в формате JSON:\\n'\n",
        "    '{\"correct\": \"грамотное предложение на русском языке\", \"error\": \"то же предложение, но с 1–3 реалистичными опечатками '\n",
        "    '(например, пропущенные буквы, переставленные соседние буквы, замена \\'е\\' на \\'ё\\' или \\'и\\' на \\'й\\', опечатки как при быстрой печати)\"}\\n'\n",
        "    'Предложение должно быть простым, разговорным, длиной 3–10 слов. Не используй кавычки внутри значений. Не добавляй пояснений. Используй меньше местоимений \"я\" и \"мне\"'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xFysbIIfX6Nw"
      },
      "outputs": [],
      "source": [
        "def generate_pair():\n",
        "    for attempt in range(3):\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": PROMPT}],\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            temperature=0.8,\n",
        "            max_tokens=120\n",
        "        )\n",
        "\n",
        "            print(response.choices[0].message.content)\n",
        "            content = response.choices[0].message.content.strip()\n",
        "            \n",
        "            if content.startswith(\"```\"):\n",
        "                content = content.split(\"\\n\", 1)[1].rsplit(\"\\n\", 1)[0]\n",
        "            data = json.loads(content)\n",
        "            if \"correct\" in data and \"error\" in data:\n",
        "                return {\"error\": data[\"error\"], \"correct\": data[\"correct\"]}\n",
        "            \n",
        "        except RateLimitError:\n",
        "            wait_time = 5 ** attempt  \n",
        "            print(f\"Лимит исчерпан. Ждём {wait_time} сек...\")\n",
        "            time.sleep(wait_time)\n",
        "        except Exception as e:\n",
        "            print(f\"Ошибка при генерации: {e}\")\n",
        "            time.sleep(1)\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset = []\n",
        "# target_size = 1100\n",
        "\n",
        "# for i in range(target_size):\n",
        "#     print(f\"Генерация {i+1}/{target_size}\")\n",
        "#     pair = generate_pair()\n",
        "#     if pair:\n",
        "#         dataset.append(pair)\n",
        "#         # Сохраняем сразу после каждого успешного примера\n",
        "#         with open(\"spell_dataset.jsonl\", \"a\", encoding=\"utf-8\") as f:\n",
        "#             f.write(json.dumps(pair, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1147\n"
          ]
        }
      ],
      "source": [
        "# Посмотрим на кол-во строк в получившемся файле\n",
        "dataset = load_dataset(\"json\", data_files=\"spell_dataset.jsonl\")\n",
        "\n",
        "print(len(dataset[\"train\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 894.12ba/s]\n",
            "Processing Files (1 / 1): 100%|██████████| 26.4kB / 26.4kB,  0.00B/s  \n",
            "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
            "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.36s/ shards]\n",
            "c:\\Users\\ksbal\\Desktop\\HW\\GenDL\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ksbal\\.cache\\huggingface\\hub\\datasets--ksbal--spell_dataset. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "No files have been modified since last commit. Skipping to prevent empty commit.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Датасет загружен: https://huggingface.co/datasets/ksbal/spell_dataset\n"
          ]
        }
      ],
      "source": [
        "hf_dataset = Dataset.from_list(dataset[\"train\"])\n",
        "\n",
        "# Сохранение на Hugging Face Hub\n",
        "# Сначала залогиньтесь:\n",
        "# huggingface-cli login\n",
        "\n",
        "# HF_REPO_ID = \"ksbal/spell_dataset\"\n",
        "\n",
        "# try:\n",
        "#     hf_dataset.push_to_hub(\n",
        "#         repo_id=HF_REPO_ID,\n",
        "#         token=\"***\", \n",
        "#         private=False,\n",
        "#         commit_message=\"Add correction dataset\"\n",
        "#     )\n",
        "#     print(f\"Датасет загружен: https://huggingface.co/datasets/{HF_REPO_ID}\")\n",
        "# except Exception as e:\n",
        "#     print(f\"Ошибка при загрузке на HF: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg9OoCu1iPkG"
      },
      "source": [
        "Я дообучу выбранную модель (например, ruGPT3-small или другую) на собранном датасете с исправлениями опечаток. Затем протестирую её на аудиозаписях, в которых whisper-small допустил ошибки.\n",
        "\n",
        "Для оценки качества я выведу 10 пар: исходный текст от Whisper и его исправленную версию, полученную с помощью дообученной модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1147"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_dataset = load_dataset(\"json\", data_files=\"spell_dataset.jsonl\")\n",
        "len(raw_dataset[\"train\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Модель\n",
        "model_name = \"UrukHan/t5-russian-spell\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Токенизация\n",
        "def preprocess_function(examples):\n",
        "    inputs = [\"Spell correct: \" + text for text in examples[\"error\"]]\n",
        "    targets = examples[\"correct\"]\n",
        "    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n",
        "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\").input_ids\n",
        "    model_inputs[\"labels\"] = labels\n",
        "    return model_inputs\n",
        "\n",
        "tokenized_dataset = raw_dataset.map(\n",
        "    preprocess_function,\n",
        "    batched=True,\n",
        "    remove_columns=[\"error\", \"correct\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Аргументы обучения\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./spell_correction_finetuned\",\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=500,\n",
        "    per_device_train_batch_size=8,       \n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=3e-5,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=100,\n",
        "    fp16=torch.cuda.is_available(),      \n",
        "    predict_with_generate=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\",\n",
        "    remove_unused_columns=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ksbal\\AppData\\Local\\Temp\\ipykernel_8096\\1345063306.py:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Seq2SeqTrainer(\n"
          ]
        }
      ],
      "source": [
        "# Trainer\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3AdSsx1SgAXr"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [216/216 08:22, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.078700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.006300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ksbal\\Desktop\\HW\\GenDL\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:3918: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('./spell_correction_finetuned\\\\tokenizer_config.json',\n",
              " './spell_correction_finetuned\\\\special_tokens_map.json',\n",
              " './spell_correction_finetuned\\\\spiece.model',\n",
              " './spell_correction_finetuned\\\\added_tokens.json')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Запускаем обучение\n",
        "trainer.train()\n",
        "\n",
        "# Сохраняем дообученную модель\n",
        "trainer.save_model(\"./spell_correction_finetuned\")\n",
        "tokenizer.save_pretrained(\"./spell_correction_finetuned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
          ]
        }
      ],
      "source": [
        "# Загружаем дообученную модель\n",
        "finetuned_model_path = \"./spell_correction_finetuned\"\n",
        "ft_tokenizer = AutoTokenizer.from_pretrained(finetuned_model_path)\n",
        "ft_model = AutoModelForSeq2SeqLM.from_pretrained(finetuned_model_path).to(device)\n",
        "\n",
        "def correct_with_finetuned(text: str) -> str:\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    input_text = \"Spell correct: \" + text\n",
        "    inputs = ft_tokenizer(input_text, return_tensors=\"pt\", max_length=128, truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = ft_model.generate(**inputs, max_length=128, num_beams=4)\n",
        "    return ft_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "\n",
        "# Получаем 10 исходных текстов\n",
        "transcriptions = []\n",
        "for url in selected_urls:\n",
        "    try:\n",
        "        transcriptions.append(transcribe_audio(url))\n",
        "    except:\n",
        "        transcriptions.append(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1] Распознано:     Александр Владимирович Попов\n",
            "    Предобученная:  Александр Владимирович Попов\n",
            "    Дообученная:    Александр Владимирович Попов\n",
            "\n",
            "[2] Распознано:     Андрей Сахаров\n",
            "    Предобученная:  Андрей Сахаров\n",
            "    Дообученная:    Андрей Сахаров\n",
            "\n",
            "[3] Распознано:     Дайон Уорвик\n",
            "    Предобученная:  Дайон Уоррен\n",
            "    Дообученная:    Дайон Уорвик\n",
            "\n",
            "[4] Распознано:     Брюс Springsteam\n",
            "    Предобученная:  Брюс. ringsteam.\n",
            "    Дообученная:    Брюс\n",
            "\n",
            "[5] Распознано:     КОУ ПОРТЕР\n",
            "    Предобученная:  КОУ ПОРТЕР\n",
            "    Дообученная:    КОМУ ПОРТЕР\n",
            "\n",
            "[6] Распознано:     Голова ломка.\n",
            "    Предобученная:  Голова ломка.\n",
            "    Дообученная:    Голова ломка\n",
            "\n",
            "[7] Распознано:     Крестный отец 2\n",
            "    Предобученная:  Крестный отец 2\n",
            "    Дообученная:    Крестный отец 2\n",
            "\n",
            "[8] Распознано:     Дай не трехо.\n",
            "    Предобученная:  Дай не трех.\n",
            "    Дообученная:    Дай не трех\n",
            "\n",
            "[9] Распознано:     Эффект бабочки.\n",
            "    Предобученная:  Эффект бабочки.\n",
            "    Дообученная:    Эффект бабочки\n",
            "\n",
            "[10] Распознано:     Старший сын\n",
            "    Предобученная:  Старший сын.\n",
            "    Дообученная:    Старший сын\n"
          ]
        }
      ],
      "source": [
        "# Выводим сравнение\n",
        "for i, raw in enumerate(transcriptions, 1):\n",
        "    orig_corr = correct_spelling(raw) \n",
        "    ft_corr = correct_with_finetuned(raw)  \n",
        "    \n",
        "    print(f\"\\n[{i}] Распознано:     {raw}\")\n",
        "    print(f\"    Предобученная:  {orig_corr}\")\n",
        "    print(f\"    Дообученная:    {ft_corr}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tnKOwwAjNsF"
      },
      "source": [
        "Я посчитаю метрики и при необходимости вернусь к дообучению модели. На этом шаге оценивается корректность выполнения, а не сами значения метрик.\n",
        "\n",
        "а) Используя эталонные транскрипции из этого датасета, я вычислю WER только для тех аудиофайлов, для которых предоставлены правильные ответы, — сначала для исходной модели whisper-small.\n",
        "\n",
        "б) Затем я оценю WER для конвейера: whisper-small + предобученная модель исправления опечаток (выбранная мной самостоятельно).\n",
        "\n",
        "в) Наконец, я посчитаю WER для конвейера: whisper-small + моя дообученная модель (на данных, собранных и дообученных мной самостоятельно)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8Ik_jNo2jNzC"
      },
      "outputs": [],
      "source": [
        "with open(\"result_array.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_ground_truth = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(raw_ground_truth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'url': 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/197f271b-b23f-4ee0-b240-e956a172d7af',\n",
              " 'text': 'жизнь других'}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_ground_truth[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Преобразуем список в словарь: {url: text}\n",
        "ground_truth = {item[\"url\"]: item[\"text\"] for item in raw_ground_truth}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/197f271b-b23f-4ee0-b240-e956a172d7af': 'жизнь других',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/3d8c8d43-f7f2-479b-a857-c90faa5e2faf': 'элтон джон',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/45161c4c-3f2c-4638-940e-a69404074ebb': 'побег из шоушенка',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/6385560c-7068-45c2-9ba7-9e061249e0a4': 'мухаммед али',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/c4f3178c-14b2-44f8-b36e-f34a47520e10': 'дневник памяти',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/0f2ef6c9-3dec-45ae-b456-8115c9419044': 'рэйф файнс',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/4711cdac-8181-4f3c-8889-77cf408f3ff2': 'нефть',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/37e917e1-1fdf-4064-a74f-57a84bcb28b9': 'золотая лихорадка',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/d203c652-509b-4c41-bdaf-f374e1c3c87e': 'служебный роман',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/c53908cc-adb1-418b-b68b-f67094fc4afd': 'браден адамс',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/a6bab1dc-059b-4f93-a2ec-baef363ddcea': 'унесенные ветром',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/dc7eedda-8db3-4ea5-abcd-d8ecb9fec734': 'бренда ли',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/29c0f7f4-9701-4e19-a4cd-874ec5397be1': 'эффект бабочки',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/fcceeeb4-5bb7-460a-853c-99c3c7bd5aef': 'андрей сахаров',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/969c8460-29a8-4c6a-ac71-bc729a6d1f3d': 'криминальное чтиво',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/22d8f014-0f11-447a-8133-fe1fb89c3e29': 'зелная книга',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/2a6d78d6-5b79-4ec1-bd9b-29b59c1960c1': 'дэнни трехо',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/51c8ac21-4179-4590-9c62-de34065cbaeb': 'билл найи',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/08890a89-c3df-4e4a-b4ac-169a347791cc': 'бабель исаак эммануилович',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/c5a115d7-015f-421c-94ce-ed9928151491': 'аристотель',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/ab7118eb-d4fc-419e-bf99-b01b3886d09a': 'крашенинников степан петрович',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/df8e6c78-0227-435c-92d0-b884bd61c91f': 'шон бин',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/2e069c1d-11ba-4a51-84b1-f182b8a2999a': 'олеша юрий карлович',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/d5bd3785-733a-4a95-b3ba-4d80ece002ee': 'однажды в америке',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/0a1ff945-8476-4f17-a579-8780800592fd': 'огни большого города',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/2de4d7fe-2bca-4bff-98be-9fd22bc58919': 'семь самураев',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/6b061312-1923-4924-97de-21e31d6f5861': 'синявский андрей донатович',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/373c13d2-0039-4ca1-a549-1563d2a8ef0a': 'крестный отец два',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/53085fa6-1df6-4d46-ae00-4ce2b89ac0ca': 'интерстеллар',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/98ba5a8c-5469-458b-a850-fd41fe24c7e1': 'алладин',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/86aaebac-a43a-4f80-a6e4-136bfb5492e3': 'головоломка',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/4ca1580f-5414-49b8-b816-72f623733105': 'ледниковый период',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/d6b51378-81b8-4b1f-8f80-0beef4a10592': 'отис реддинг',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/d92c0f04-21ec-4578-98ec-d05602683126': 'бобби винтон',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/47b9b402-e832-438d-ad85-3f7375867e4a': 'коул портер',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/236b63a8-8f37-444d-8340-25324620e985': 'адвокат дьявола',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/ba9e8621-7c94-46aa-93de-abb816732da7': 'отступники',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/871a6ddc-77b3-45e0-ab4d-2bdcddb78515': 'звздные войны эпизод пятый империя наносит ответный удар',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/2b9c598f-c08f-43eb-ac28-72cf962a9a05': 'ирония судьбы или с лгким паром',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/3274fc24-5460-43f4-8846-b77ffd73a202': 'брат',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/bbc64f47-2cfe-4cce-944d-2022fef45357': 'три идиота',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/776a335c-4817-4ed4-8a63-4b88bfaf1c2d': 'мой сосед тоторо',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/537c7e5c-fda8-46f2-8395-4420dd34dec5': 'бальмонт константин дмитриевич',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/ed3f4cd7-801b-4d3c-a237-a9d662d04fd5': 'фил коллинз',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/f72678b7-c101-402f-bf8c-825bf4d70418': 'город бога',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/9e07115e-bb04-49ad-bab5-c31c1ab70b27': 'джеки робинсон',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/eb8495aa-d429-4326-9e42-f6786555647a': 'отель руанда',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/46a1b365-6ee9-43d6-8a36-42a37c40dbc0': 'кенни роджерс',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/8eec6bf4-818c-4852-8063-0bcc5d2e7175': 'гладиатор',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/5fdd45c8-59c9-4c90-bf81-e426cf597f40': 'джулианна мур',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/d69a744d-0510-4a61-9705-95901544390f': 'эмма стоун',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/56280403-d892-44fb-864a-81fb2943c77c': 'гроздья гнева',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/84c7ed3f-4010-4de2-8a30-88a312be0bba': 'смоки робинсон',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/0a450eae-9d55-4bf0-aba8-a6f2e1162706': 'огни большого города',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/ce29f3d2-8c47-4466-a2b5-7bcb73b0eb02': 'воин',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/4201a552-ca79-4a67-9b2a-126d75d0a3be': 'римские каникулы',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/1822f91a-1888-44fa-9104-f4d06d864010': 'нокдаун',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/59d62edf-fea9-4825-8f74-9e9927280f1e': 'зигмунд фрейд',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/eb158b7a-c882-495f-955c-a20b23c3b4cb': 'таксист',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/77d390c1-45ad-414d-9843-640527a52018': 'иван павлов',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/703e7d9c-b170-4762-b5d3-c4fa8e4be0e8': 'николай коперник',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/6322d6cd-0928-4b4d-b96d-7cf78a86d7e6': 'фернандо ботеро',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/b85b751d-b0b9-4b74-a62f-53b26a0d95ca': 'ханс хартунг',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/66d66f3c-0ead-4714-95c7-6e6750fb8539': 'мушкетов иван васильевич',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/1c215f06-d03e-4094-96c7-db5b3c3d1105': 'пол маккартни',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/adaaff15-9678-41d6-abe1-84ee20c24c44': 'умница уилл хантинг',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/712d06b3-ebd5-4bc0-ba8d-5fd1e7969458': 'индиана джонс и последний крестовый поход',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/533e00e4-0e05-4319-b82e-411ab57b8802': 'бейб дидриксон захариас',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/13256106-9e6e-46fc-9c22-efec2a7de09f': 'джим торп',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/286bd6c3-a984-4eb6-8955-b27643b1cfd7': 'ходасевич владислав фелицианович',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/4bd0ad25-e86a-4275-85b6-4d11ac96cfdc': 'мой отец и мой сын',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/7bb27c39-5384-4e77-a6c8-bf9789c00337': 'космическая одиссея две тысячи первого года',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/759edbe2-5d4f-4c88-acdc-439fcd5eb6c1': 'майкл фарадей',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/1972e18d-dc62-418f-8a00-61f3235bbab9': 'брэд питт',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/3159d866-1c94-41ed-a274-e8ccee3fb966': 'гарри поттер и дары смерти часть два',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/f41d0849-5116-4900-b4c5-c9e201c30e06': 'четыреста ударов',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/4c0f8f80-99f2-4dba-b54f-1860e07af180': 'гарри поттер и дары смерти часть два',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/2144ca43-13e4-49ad-9c8e-5a5ecf8599d9': 'распутин валентин григорьевич',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/eebe7151-43f7-4e5f-af3d-d7a1a3ab2197': 'александр владимирович попов',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/0b495d2e-a15e-4ee6-8283-316fb821abf2': 'унесенные ветром',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/38e898d9-0707-4b1f-a01a-c2da05315be6': 'ходячий замок',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/ca50a690-f1af-4a75-84e7-a8b121eff5e7': 'джон гудман',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/18463/6aa3e60d-d38a-4828-8e07-5cb28ce1677c': 'ультиматум борна',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/1f418f48-7d16-41c4-b1ec-a06ec58aacfd': 'старший сын',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/f3a2f832-413e-49e7-a332-f565694c7604': 'франсиско писарро',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/5baa289b-4373-47ff-8203-4462e052510f': 'джерард батлер',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/25c34061-fef9-4563-a813-e36b910f1e70': 'рене декарт',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/52f5c4dd-0c56-4e90-9f9b-162e2eab83f5': 'арета франклин',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/86cae6ee-fe19-43b7-b6c7-cd30736167b1': 'жан поль сартр',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/e3c3340d-2ac2-4c10-be96-8ee64b425d7b': 'на игле',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/09c0c412-2316-4bf4-9f92-8349067de618': 'брюс спрингстин',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/2021744/00760e69-35b8-4c65-84f6-c1d0e82907c2': 'помни',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/ed83b5df-882e-45ce-80b5-80a174a1c10c': 'элизабет бэнкс',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/163e0da8-750f-45d4-b5d5-8982fb060c12': 'новый кинотеатр парадизо',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1879367/af0b23ef-7519-49e0-b32c-cab81f50f2f7': 'крепкий орешек',\n",
              " 'http://storage.mds.yandex.net:80/get-voicetoloka/1872575/f9d9fa24-0e3c-430f-8e42-622a0fa0c6a5': 'кейт буш'}"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Отфильтровано 96 URL с эталонными транскрипциями\n"
          ]
        }
      ],
      "source": [
        "# Фильтр для правильных ответов\n",
        "filtered_lines = [url for url in lines if url in ground_truth]\n",
        "\n",
        "print(f\"Отфильтровано {len(filtered_lines)} URL с эталонными транскрипциями\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torcheval.metrics import WordErrorRate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_wer(predictions, references):\n",
        "    metric = WordErrorRate()\n",
        "    metric.update(predictions, references)\n",
        "    return metric.compute().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Собираем эталоны и предсказания\n",
        "refs = []\n",
        "preds_whisper = []\n",
        "preds_pretrained = []\n",
        "preds_finetuned = []\n",
        "\n",
        "for url in filtered_lines:\n",
        "    ref = ground_truth[url].strip().lower()\n",
        "    try:\n",
        "        raw = transcribe_audio(url).strip().lower()\n",
        "        corr_pre = correct_spelling(raw).strip().lower()\n",
        "        corr_ft = correct_with_finetuned(raw).strip().lower()\n",
        "        \n",
        "        refs.append(ref)\n",
        "        preds_whisper.append(raw)\n",
        "        preds_pretrained.append(corr_pre)\n",
        "        preds_finetuned.append(corr_ft)\n",
        "    except Exception as e:\n",
        "        print(f\"Ошибка {e}\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WER (Whisper-small):          0.4957\n",
            "WER (Whisper + предобученная): 0.8087\n",
            "WER (Whisper + дообученная):   0.4217\n"
          ]
        }
      ],
      "source": [
        "wer_whisper = compute_wer(preds_whisper, refs)\n",
        "wer_pretrained = compute_wer(preds_pretrained, refs)\n",
        "wer_finetuned = compute_wer(preds_finetuned, refs)\n",
        "\n",
        "print(f\"WER (Whisper-small):          {wer_whisper:.4f}\")\n",
        "print(f\"WER (Whisper + предобученная): {wer_pretrained:.4f}\")\n",
        "print(f\"WER (Whisper + дообученная):   {wer_finetuned:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sUQNgLjj4lQ"
      },
      "source": [
        "Я проведу максимально глубокий research и серию экспериментов в рамках бесплатного Google Colab, чтобы добиться наилучшего качества решения задачи speech-to-text:\n",
        "\n",
        "* Подберу и протестирую альтернативные предобученные ASR-модели, сравнивая их WER на эталонных транскрипциях, чтобы найти ту, что даёт меньше опечаток, чем whisper-small.\n",
        "* Опробую несколько моделей для исправления ошибок (spell-correction) — как предобученные, так и дообученные на собственном датасете — и выберу лучшую по итоговому WER.\n",
        "* Возьму эту лучшую модель и улучшу её, адаптировав подход из шага 4: немного изменю данные, стратегию дообучения или гиперпараметры. Обосную, почему выбранная модификация теоретически должна повысить качество, и проверю это эмпирически. По результатам сделаю вывод: удалось ли улучшить WER, а если нет — предположу возможные причины."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "from evaluate import load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "stt_models = {\n",
        "    \"whisper-small\": (\n",
        "        WhisperProcessor.from_pretrained(\"openai/whisper-small\"),\n",
        "        WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(device),\n",
        "        \"whisper\"\n",
        "    ),\n",
        "    \"wav2vec2-ru\": (\n",
        "        Wav2Vec2Processor.from_pretrained(\"bond005/wav2vec2-large-ru-golos\"),\n",
        "        Wav2Vec2ForCTC.from_pretrained(\"bond005/wav2vec2-large-ru-golos\").to(device),\n",
        "        \"wav2vec2\"\n",
        "    )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_urls = random.sample(filtered_lines, k=min(10, len(filtered_lines)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Тестируем модель: whisper-small\n",
            "[1] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/ca50a690-f1af-4a75-84e7-a8b121eff5e7\n",
            "Истина:     джон гудман\n",
            "Предсказание:     джон гудман\n",
            "[2] URL: http://storage.mds.yandex.net:80/get-voicetoloka/2021744/969c8460-29a8-4c6a-ac71-bc729a6d1f3d\n",
            "Истина:     криминальное чтиво\n",
            "Предсказание:     криминальная чтива.\n",
            "[3] URL: http://storage.mds.yandex.net:80/get-voicetoloka/2021744/6385560c-7068-45c2-9ba7-9e061249e0a4\n",
            "Истина:     мухаммед али\n",
            "Предсказание:     мохаммед али\n",
            "[4] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/af0b23ef-7519-49e0-b32c-cab81f50f2f7\n",
            "Истина:     крепкий орешек\n",
            "Предсказание:     крепкий орешек.\n",
            "[5] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/236b63a8-8f37-444d-8340-25324620e985\n",
            "Истина:     адвокат дьявола\n",
            "Предсказание:     адвокат делала\n",
            "[6] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/4ca1580f-5414-49b8-b816-72f623733105\n",
            "Истина:     ледниковый период\n",
            "Предсказание:     ледниковый период\n",
            "[7] URL: http://storage.mds.yandex.net:80/get-voicetoloka/2021744/53085fa6-1df6-4d46-ae00-4ce2b89ac0ca\n",
            "Истина:     интерстеллар\n",
            "Предсказание:     интерстеллер\n",
            "[8] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/51c8ac21-4179-4590-9c62-de34065cbaeb\n",
            "Истина:     билл найи\n",
            "Предсказание:     бил на и\n",
            "[9] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/fcceeeb4-5bb7-460a-853c-99c3c7bd5aef\n",
            "Истина:     андрей сахаров\n",
            "Предсказание:     андрей сахаров\n",
            "[10] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/25c34061-fef9-4563-a813-e36b910f1e70\n",
            "Истина:     рене декарт\n",
            "Предсказание:     рене-декарт.\n",
            "WER для whisper-small: 0.5789\n",
            "\n",
            "Тестируем модель: wav2vec2-ru\n",
            "[1] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/ca50a690-f1af-4a75-84e7-a8b121eff5e7\n",
            "Истина:     джон гудман\n",
            "Предсказание:     джон гудман\n",
            "[2] URL: http://storage.mds.yandex.net:80/get-voicetoloka/2021744/969c8460-29a8-4c6a-ac71-bc729a6d1f3d\n",
            "Истина:     криминальное чтиво\n",
            "Предсказание:     криминальная чтива\n",
            "[3] URL: http://storage.mds.yandex.net:80/get-voicetoloka/2021744/6385560c-7068-45c2-9ba7-9e061249e0a4\n",
            "Истина:     мухаммед али\n",
            "Предсказание:     махамед али\n",
            "[4] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/af0b23ef-7519-49e0-b32c-cab81f50f2f7\n",
            "Истина:     крепкий орешек\n",
            "Предсказание:     крепкий орешек\n",
            "[5] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/236b63a8-8f37-444d-8340-25324620e985\n",
            "Истина:     адвокат дьявола\n",
            "Предсказание:     адвокат дьявола\n",
            "[6] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1879367/4ca1580f-5414-49b8-b816-72f623733105\n",
            "Истина:     ледниковый период\n",
            "Предсказание:     летниковый период\n",
            "[7] URL: http://storage.mds.yandex.net:80/get-voicetoloka/2021744/53085fa6-1df6-4d46-ae00-4ce2b89ac0ca\n",
            "Истина:     интерстеллар\n",
            "Предсказание:     интерстеллар\n",
            "[8] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/51c8ac21-4179-4590-9c62-de34065cbaeb\n",
            "Истина:     билл найи\n",
            "Предсказание:     билл найи\n",
            "[9] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/fcceeeb4-5bb7-460a-853c-99c3c7bd5aef\n",
            "Истина:     андрей сахаров\n",
            "Предсказание:     андрей сахаров\n",
            "[10] URL: http://storage.mds.yandex.net:80/get-voicetoloka/1872575/25c34061-fef9-4563-a813-e36b910f1e70\n",
            "Истина:     рене декарт\n",
            "Предсказание:     ренедекарт\n",
            "WER для wav2vec2-ru: 0.3158\n"
          ]
        }
      ],
      "source": [
        "wer_metric = load(\"wer\")\n",
        "\n",
        "results = {}\n",
        "for name, (processor, model, model_type) in stt_models.items():\n",
        "    print(f\"\\nТестируем модель: {name}\")\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    for i, url in enumerate(test_urls, 1):\n",
        "        if url not in ground_truth:\n",
        "            continue\n",
        "\n",
        "        ref = ground_truth[url].strip().lower()\n",
        "        try:\n",
        "            response = requests.get(url, timeout=30)\n",
        "            audio_data, sr = sf.read(io.BytesIO(response.content), dtype='float32')\n",
        "\n",
        "            if audio_data.ndim > 1:\n",
        "                audio_data = audio_data.mean(axis=1)\n",
        "\n",
        "            if sr != 16000:\n",
        "                audio_tensor = torch.tensor(audio_data, dtype=torch.float32)\n",
        "                audio_resampled = torchaudio.functional.resample(audio_tensor, orig_freq=sr, new_freq=16000)\n",
        "                audio_data = audio_resampled.numpy()\n",
        "                sr = 16000\n",
        "\n",
        "            if model_type == \"whisper\":\n",
        "                inputs = processor(audio_data, sampling_rate=sr, return_tensors=\"pt\").input_features.to(device)\n",
        "                forced_ids = processor.get_decoder_prompt_ids(language=\"ru\", task=\"transcribe\")\n",
        "                with torch.no_grad():\n",
        "                    outputs = model.generate(inputs, forced_decoder_ids=forced_ids)\n",
        "                pred = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "            else:  # wav2vec2\n",
        "                inputs = processor(audio_data, sampling_rate=sr, return_tensors=\"pt\", padding=True).input_values.to(device)\n",
        "                with torch.no_grad():\n",
        "                    logits = model(inputs).logits\n",
        "                pred_ids = torch.argmax(logits, dim=-1)\n",
        "                pred = processor.batch_decode(pred_ids)[0]\n",
        "\n",
        "            pred = pred.strip().lower()\n",
        "            predictions.append(pred)\n",
        "            references.append(ref)\n",
        "\n",
        "            print(f\"[{i}] URL: {url}\")\n",
        "            print(f\"Истина:     {ground_truth[url]}\")\n",
        "            print(f\"Предсказание:     {pred}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"[{i}] URL: {url}\")\n",
        "            print(f\"Ошибка: {e}\")\n",
        "\n",
        "    # Подсчёт WER\n",
        "    if predictions:\n",
        "        wer = wer_metric.compute(predictions=predictions, references=references)\n",
        "        results[name] = wer\n",
        "        print(f\"WER для {name}: {wer:.4f}\")\n",
        "    else:\n",
        "        print(f\"Нет валидных предсказаний для {name}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNA0WBwajj0aat4A693n8Zo",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
